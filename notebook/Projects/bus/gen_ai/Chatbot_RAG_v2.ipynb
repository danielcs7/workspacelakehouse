{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d079578-172d-4b74-8878-5f293a74f1d9",
   "metadata": {},
   "source": [
    "### RAG with Tabalar Data and Vector Memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e0d65b-ae27-46e1-8664-03666950c929",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName('Chatbot_rag_v2') \\\n",
    "    .config(\"spark.jars\", \"/opt/spark/jars/iceberg-spark-runtime-3.5_2.12-1.6.0.jar\") \\\n",
    "    .config(\"spark.sql.extensions\", \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\") \\\n",
    "    .config(\"spark.sql.catalog.local\", \"org.apache.iceberg.spark.SparkCatalog\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog.type\", \"hive\") \\\n",
    "    .config(\"spark.sql.catalog.local.warehouse\", \"s3a://datalake/iceberg\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "#Ajuste de log WARN log para ERROR\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e24615-d448-44fa-bd6c-7e51606089fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain==0.2.17\n",
    "# !pip install langchain_community==0.2.19\n",
    "# !pip install -qU langchain-ollama==0.1.3\n",
    "# !pip install -qU langchain-qdrant==0.1.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a748c12c-740a-4adc-803f-d9650e0e6b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3411b169-9c63-462e-99af-dc72ef58d267",
   "metadata": {},
   "source": [
    "### Visualizar e pegar uma amostra dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c401cd-8af0-47dc-b39f-8b3d5140a9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"Select * from iceberg.silver.tbl_silver_olhovivo\").limit(10).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37b576d-7cb4-424e-b9cd-027f4b514213",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.sql(\"\"\"\n",
    "    Select\n",
    "    c,\n",
    "    cl,\n",
    "    sl,\n",
    "    lt0,\n",
    "    lt1,\n",
    "    qv\n",
    "    \n",
    "    from iceberg.silver.tbl_silver_olhovivo \"\"\"\n",
    ").limit(10)\n",
    "\n",
    "df.createOrReplaceTempView(\"vw_silver_olhovivo\")\n",
    "\n",
    "spark.sql(\"select * from vw_silver_olhovivo\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f40066b-5793-429b-b477-dc2c91cb9a5a",
   "metadata": {},
   "source": [
    "## Fun√ß√µes Auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d351fa-2f31-42af-ace2-9abfa8ba0760",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clear_sql(genereted_sql):\n",
    "    \"\"\"Remove markdown code blocks\"\"\"\n",
    "    sql = re.sub(r\"```sql|```\", \"\", genereted_sql, flags=re.IGNORECASE).strip()\n",
    "    return sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4b1a79-50dc-4874-9e0d-3019143184a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metadata(table_name):\n",
    "    df = spark.sql(f\"SELECT * FROM {table_name} LIMIT 1;\")\n",
    "    columns = \"\\n\".join([f\"- {f.name}: {f.dataType.simpleString()}\" for f in df.schema])\n",
    "    return f\"Tabela: {table_name}\\n\\nColunas:\\n{columns}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0fbaaa-85cd-498f-a6c8-77326b5a8b90",
   "metadata": {},
   "source": [
    "## Qdrant Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27747b9a-3328-4439-a925-400e88a01c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv('../.env')\n",
    "OLLAMA_API_URL = os.getenv(\"OLLAMA_API_URL\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefad4d3-4208-40b2-8c44-fbb7680ab5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "embedding = OllamaEmbeddings(model=\"mistral:latest\", base_url=OLLAMA_API_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e953e044-9c89-4836-87d0-410ff90b99da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria cole√ß√£o para armazenar os embeddings \n",
    "\n",
    "from langchain_qdrant import QdrantVectorStore\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import Distance, VectorParams\n",
    "from qdrant_client.models import Distance, VectorParams, PointStruct, Filter, FieldCondition, MatchValue\n",
    "from langchain_core.documents import Document\n",
    "import uuid\n",
    "\n",
    "client = QdrantClient(\":memory:\")\n",
    "\n",
    "collection_name =\"olho_vivo\"\n",
    "\n",
    "client.create_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors_config=VectorParams(size=4096, distance=Distance.COSINE),\n",
    ")\n",
    "\n",
    "vector_store = QdrantVectorStore(\n",
    "    client=client,\n",
    "    collection_name=collection_name,\n",
    "    embedding=embedding,\n",
    ")\n",
    "\n",
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e40b13-a011-4492-811e-29b91884520d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./Memory.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c46fee-ccd6-4abe-b3ff-d12e2ec22af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "qdrant_memory = QdrantMemory(client, embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee9657b-d8ea-4c7c-82c2-a7ba71c4a77c",
   "metadata": {},
   "source": [
    "## Iniciar Mistral 7B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb1154f-1eb4-49ef-8895-5eeb4480e233",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "# llm = ChatOllama(\n",
    "#     model=\"mistral:latest\", \n",
    "#     base_url=OLLAMA_API_URL,\n",
    "#     temperature = 0.3,\n",
    " \n",
    "# )\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model=\"mistral:latest\", \n",
    "    base_url=OLLAMA_API_URL,\n",
    "    temperature=0.3,\n",
    "    num_predict=200,\n",
    "    top_k=20,\n",
    "    repeat_penalty=1.2\n",
    "    \n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ee7fa3-4d71-4e81-bf4a-1eec57e33360",
   "metadata": {},
   "source": [
    "### Configurar Promps: Roles System e Human"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f542b5ac-2097-4938-a91e-9d208c1e55cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "# Prompt para gerar SQL (Spark)\n",
    "prompt_sql = ChatPromptTemplate.from_messages([\n",
    "    SystemMessagePromptTemplate.from_template(\"Voc√™ √© um especialista em dados. Gere apenas a consulta SQL.\"),\n",
    "    HumanMessagePromptTemplate.from_template(\n",
    "        \"Com base na estrutura da tabela abaixo:\\n\\n{schema}\\n\\n\"\n",
    "        \"Escreva uma consulta SQL (somente a SQL) para responder:\\n{question}\"\n",
    "    )\n",
    "])\n",
    "\n",
    "\n",
    "# Prompt para retornar resultado ao usuario\n",
    "prompt_response = ChatPromptTemplate.from_messages([\n",
    "    SystemMessagePromptTemplate.from_template(\"Voc√™ √© um assistente de dados.\"),\n",
    "    HumanMessagePromptTemplate.from_template(\n",
    "        \"Pergunta: {question}\\n\\nResultado da consulta:\\n{result}\\n\\n\"\n",
    "        \"Gere uma resposta clara e amig√°vel para o usu√°rio contendo apenas os resultados da consulta.\"\n",
    "    )\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8d5a2f-6fa5-43c0-a53e-84ff9ddd5c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fun√ß√£o para gerar resposta com RAG (Tabela + Qdrant)\n",
    "def augmented_response(question, table_name):\n",
    "    print(f\"\\nüí¨ question : {question}\")\n",
    "\n",
    "    #Obter metadados da tabela\n",
    "    schema_txt = get_metadata(table_name)\n",
    "\n",
    "    # Buscar embeddings no Qdrant (Memoria)\n",
    "    docs = retriever.invoke(question)\n",
    "    context = \"\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "    # Gerar o SQL da query com base na pergunta\n",
    "    sql_chain = prompt_sql | llm\n",
    "    sql_result = sql_chain.invoke({\n",
    "        \"question\": question,\n",
    "        \"schema\": schema_txt,\n",
    "        \"context\": context\n",
    "    }).content.strip()\n",
    "\n",
    "\n",
    "    sql_query=clear_sql(sql_result)\n",
    "    print(f\"\\nü§ñüí° Generated SQL: {sql_query}\")\n",
    "\n",
    "    # Executar query no Spark\n",
    "    try:\n",
    "\n",
    "        result_df = spark.sql(sql_query).toPandas().to_dict(orient=\"records\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Erro na execu√ß√£o da SQL: {e}\")\n",
    "        return\n",
    "\n",
    "    # Gera resposta amig√°vel para retornar ao usuario\n",
    "    response_chain = prompt_response | llm\n",
    "    response = response_chain.invoke({\n",
    "        \"question\": question,\n",
    "        \"result\": result_df\n",
    "    }).content.strip()\n",
    "\n",
    "    print(f\"\\nü§ñ response : {response}\")\n",
    "\n",
    "\n",
    "    # Armazena pergunta + SQL + resultado + score na memoria Qdrant\n",
    "    qdrant_memory.instruct(\n",
    "        question, \n",
    "        sql_query, \n",
    "        metadata={\n",
    "            \"table\": table_name, \n",
    "            \"result\": result_df, \n",
    "            \"schema\": schema_txt, \n",
    "            \"score\": 1}\n",
    "    )\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c73b49a-39e8-4c3a-818d-3defdff46d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = augmented_response(question, table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9988d0e7-b978-43e0-bc5a-da0cd03dea6d",
   "metadata": {},
   "source": [
    "### Listar Exemplos de Consultas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c7b754-5d24-4871-93db-985fc9878d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "qdrant_memory.list_embedding_content()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00af2a02-41ee-460f-b86a-7d08d15317f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "qdrant_memory.list_scored_point(\"question here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd2b65d-7df0-45a0-a857-de75c44a4dad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "77b3eb11-da4d-422e-a4bd-51bc35a9e46c",
   "metadata": {},
   "source": [
    "## \"Ensinar\" refinar comportamento manualmente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fe912d-1fe9-432e-b784-f18fb8363406",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query =\"\"\" \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82862d8e-3d07-4de9-8c38-59cf83acb291",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(sql_query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21f971b-5739-4ec9-bd45-945928a62b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name = \"table_name\"\n",
    "pergunta = \"\"\n",
    "schema_txt = get_metadata(table_name)\n",
    "\n",
    "qdrant_memory.instruct(\n",
    "    pergunta,\n",
    "    sql_query, \n",
    "    metadados=metadata={\"table\": table_name, \"result\": result_df, \"schema\": schema_txt, \"score\": 1}\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
